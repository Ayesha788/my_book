"use strict";(globalThis.webpackChunkmy_book_site=globalThis.webpackChunkmy_book_site||[]).push([[204],{6061:(n,e,i)=>{i.r(e),i.d(e,{assets:()=>l,contentTitle:()=>r,default:()=>u,frontMatter:()=>s,metadata:()=>o,toc:()=>c});const o=JSON.parse('{"id":"chapter2-digital-twin","title":"Chapter 2: Digital Twin - Simulating Humanoid Robots","description":"Introduction to Digital Twin Technology","source":"@site/docs/chapter2-digital-twin.md","sourceDirName":".","slug":"/chapter2-digital-twin","permalink":"/my_book/docs/chapter2-digital-twin","draft":false,"unlisted":false,"editUrl":"https://github.com/Ayesha788/my_book/tree/main/docs/chapter2-digital-twin.md","tags":[],"version":"current","frontMatter":{},"sidebar":"tutorialSidebar","previous":{"title":"Chapter 1: ROS 2 Fundamentals - The Robotic Nervous System","permalink":"/my_book/docs/chapter1-ros2"},"next":{"title":"Chapter 3: AI-Robot Brain - NVIDIA Isaac Integration","permalink":"/my_book/docs/chapter3-isaac"}}');var t=i(4848),a=i(8453);const s={},r="Chapter 2: Digital Twin - Simulating Humanoid Robots",l={},c=[{value:"Introduction to Digital Twin Technology",id:"introduction-to-digital-twin-technology",level:2},{value:"Gazebo Simulation Environment",id:"gazebo-simulation-environment",level:2},{value:"Key Features of Gazebo:",id:"key-features-of-gazebo",level:3},{value:"Installing Gazebo with ROS 2",id:"installing-gazebo-with-ros-2",level:3},{value:"Setting up a Humanoid Robot in Gazebo",id:"setting-up-a-humanoid-robot-in-gazebo",level:2},{value:"Robot Configuration",id:"robot-configuration",level:3},{value:"Example Gazebo Integration in URDF",id:"example-gazebo-integration-in-urdf",level:3},{value:"Physics Simulation Setup",id:"physics-simulation-setup",level:2},{value:"Gravity and Environment Configuration",id:"gravity-and-environment-configuration",level:3},{value:"Sensor Simulation",id:"sensor-simulation",level:3},{value:"LiDAR Sensor",id:"lidar-sensor",level:4},{value:"IMU Sensor",id:"imu-sensor",level:4},{value:"Unity Integration for High-Fidelity Visualization",id:"unity-integration-for-high-fidelity-visualization",level:2},{value:"Unity-ROS 2 Bridge Setup",id:"unity-ros-2-bridge-setup",level:3},{value:"Basic Unity-ROS 2 Connection",id:"basic-unity-ros-2-connection",level:3},{value:"Creating a Simulation Environment",id:"creating-a-simulation-environment",level:2},{value:"Launch File for Gazebo Simulation",id:"launch-file-for-gazebo-simulation",level:3},{value:"Running the Simulation",id:"running-the-simulation",level:2},{value:"Starting the Simulation",id:"starting-the-simulation",level:3},{value:"Verifying Sensor Data",id:"verifying-sensor-data",level:3},{value:"Practice Tasks",id:"practice-tasks",level:2},{value:"Summary",id:"summary",level:2}];function d(n){const e={code:"code",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",strong:"strong",ul:"ul",...(0,a.R)(),...n.components},{Diagram:i}=e;return i||function(n,e){throw new Error("Expected "+(e?"component":"object")+" `"+n+"` to be defined: you likely forgot to import, pass, or provide it.")}("Diagram",!0),(0,t.jsxs)(t.Fragment,{children:[(0,t.jsx)(e.header,{children:(0,t.jsx)(e.h1,{id:"chapter-2-digital-twin---simulating-humanoid-robots",children:"Chapter 2: Digital Twin - Simulating Humanoid Robots"})}),"\n",(0,t.jsx)(e.h2,{id:"introduction-to-digital-twin-technology",children:"Introduction to Digital Twin Technology"}),"\n",(0,t.jsx)(e.p,{children:"Digital Twin technology creates virtual replicas of physical systems, allowing for simulation, analysis, and optimization before implementing in the real world. In robotics, digital twins are crucial for testing and validating robot behaviors in safe, controlled virtual environments before deployment on actual hardware."}),"\n",(0,t.jsx)(e.p,{children:"For humanoid robotics, digital twins enable:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Safe testing of complex locomotion algorithms"}),"\n",(0,t.jsx)(e.li,{children:"Sensor simulation and validation"}),"\n",(0,t.jsx)(e.li,{children:"Physics-based interaction testing"}),"\n",(0,t.jsx)(e.li,{children:"Control system development without hardware risk"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"gazebo-simulation-environment",children:"Gazebo Simulation Environment"}),"\n",(0,t.jsx)(e.p,{children:"Gazebo is a powerful 3D simulation environment that provides realistic physics simulation, high-quality graphics, and convenient programmatic interfaces. It's widely used in the ROS ecosystem for robotics simulation."}),"\n",(0,t.jsx)(e.h3,{id:"key-features-of-gazebo",children:"Key Features of Gazebo:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"Physics simulation with ODE, Bullet, Simbody, or DART engines"}),"\n",(0,t.jsx)(e.li,{children:"High-quality graphics rendering"}),"\n",(0,t.jsx)(e.li,{children:"Sensor simulation (cameras, LiDAR, IMU, etc.)"}),"\n",(0,t.jsx)(e.li,{children:"Realistic lighting and environment modeling"}),"\n",(0,t.jsx)(e.li,{children:"Plugin architecture for custom functionality"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"installing-gazebo-with-ros-2",children:"Installing Gazebo with ROS 2"}),"\n",(0,t.jsx)(e.p,{children:"For ROS 2 Humble, Gazebo can be installed as part of the desktop package or separately:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Install Gazebo Garden (recommended for ROS 2 Humble)\nsudo apt install ros-humble-gazebo-*\n\n# Install the ROS 2 Gazebo bridge\nsudo apt install ros-humble-gazebo-ros-pkgs\n"})}),"\n",(0,t.jsx)(e.h2,{id:"setting-up-a-humanoid-robot-in-gazebo",children:"Setting up a Humanoid Robot in Gazebo"}),"\n",(0,t.jsx)(e.h3,{id:"robot-configuration",children:"Robot Configuration"}),"\n",(0,t.jsx)(e.p,{children:"To simulate a humanoid robot in Gazebo, you need:"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"URDF Model"}),": A detailed robot description file"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Gazebo Plugins"}),": For physics simulation and sensor integration"]}),"\n",(0,t.jsxs)(e.li,{children:[(0,t.jsx)(e.strong,{children:"Launch Files"}),": To start the simulation with proper configuration"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"example-gazebo-integration-in-urdf",children:"Example Gazebo Integration in URDF"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-xml",children:'<?xml version="1.0"?>\n<robot name="humanoid_robot" xmlns:xacro="http://www.ros.org/wiki/xacro">\n  \x3c!-- Include Gazebo-specific plugins --\x3e\n  <gazebo>\n    <plugin name="gazebo_ros_control" filename="libgazebo_ros_control.so">\n      <robotNamespace>/humanoid_robot</robotNamespace>\n    </plugin>\n  </gazebo>\n\n  \x3c!-- Link definitions with Gazebo properties --\x3e\n  <link name="base_link">\n    <visual>\n      <geometry>\n        <box size="0.2 0.1 0.1"/>\n      </geometry>\n    </visual>\n    <collision>\n      <geometry>\n        <box size="0.2 0.1 0.1"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="5.0"/>\n      <inertia ixx="0.1" ixy="0.0" ixz="0.0" iyy="0.1" iyz="0.0" izz="0.1"/>\n    </inertial>\n  </link>\n\n  \x3c!-- Example joint with physics properties --\x3e\n  <joint name="hip_joint" type="revolute">\n    <parent link="base_link"/>\n    <child link="left_leg"/>\n    <origin xyz="0 0.1 -0.1" rpy="0 0 0"/>\n    <axis xyz="0 0 1"/>\n    <limit lower="-1.57" upper="1.57" effort="100" velocity="1.0"/>\n    <dynamics damping="0.1" friction="0.0"/>\n  </joint>\n\n  <link name="left_leg">\n    <visual>\n      <geometry>\n        <cylinder length="0.5" radius="0.05"/>\n      </geometry>\n    </visual>\n    <collision>\n      <geometry>\n        <cylinder length="0.5" radius="0.05"/>\n      </geometry>\n    </collision>\n    <inertial>\n      <mass value="2.0"/>\n      <inertia ixx="0.05" ixy="0.0" ixz="0.0" iyy="0.05" iyz="0.0" izz="0.001"/>\n    </inertial>\n  </link>\n</robot>\n'})}),"\n",(0,t.jsx)(e.h2,{id:"physics-simulation-setup",children:"Physics Simulation Setup"}),"\n",(0,t.jsx)(e.h3,{id:"gravity-and-environment-configuration",children:"Gravity and Environment Configuration"}),"\n",(0,t.jsx)(e.p,{children:"Gazebo allows detailed configuration of physics properties:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-xml",children:"<sdf version='1.7'>\n  <world name='default'>\n    <physics type='ode'>\n      <gravity>0 0 -9.8</gravity>\n      <max_step_size>0.001</max_step_size>\n      <real_time_factor>1.0</real_time_factor>\n      <real_time_update_rate>1000</real_time_update_rate>\n    </physics>\n\n    \x3c!-- Include a ground plane --\x3e\n    <include>\n      <uri>model://ground_plane</uri>\n    </include>\n\n    \x3c!-- Include sun for lighting --\x3e\n    <include>\n      <uri>model://sun</uri>\n    </include>\n  </world>\n</sdf>\n"})}),"\n",(0,t.jsx)(e.h3,{id:"sensor-simulation",children:"Sensor Simulation"}),"\n",(0,t.jsx)(i,{title:"Sensor Simulation in Gazebo",description:"A diagram showing how sensors are integrated into the Gazebo simulation. The humanoid robot model has multiple sensors attached: a LiDAR on the head, cameras on the torso, IMU sensors distributed across the body, and contact sensors on the feet. Each sensor publishes data to ROS 2 topics. The Gazebo physics engine processes sensor data based on the robot's position and the environment.",children:(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{src:"/img/diagrams/sensor-simulation.svg",alt:"Sensor Simulation"})})}),"\n",(0,t.jsx)(e.p,{children:"Gazebo can simulate various sensors crucial for humanoid robotics:"}),"\n",(0,t.jsx)(e.h4,{id:"lidar-sensor",children:"LiDAR Sensor"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-xml",children:'<gazebo reference="lidar_link">\n  <sensor type="ray" name="humanoid_lidar">\n    <pose>0 0 0 0 0 0</pose>\n    <visualize>true</visualize>\n    <update_rate>10</update_rate>\n    <ray>\n      <scan>\n        <horizontal>\n          <samples>720</samples>\n          <resolution>1</resolution>\n          <min_angle>-3.14159</min_angle>\n          <max_angle>3.14159</max_angle>\n        </horizontal>\n      </scan>\n      <range>\n        <min>0.1</min>\n        <max>30.0</max>\n        <resolution>0.01</resolution>\n      </range>\n    </ray>\n    <plugin name="lidar_controller" filename="libgazebo_ros_ray_sensor.so">\n      <ros>\n        <namespace>/humanoid_robot</namespace>\n        <remapping>~/out:=scan</remapping>\n      </ros>\n      <output_type>sensor_msgs/LaserScan</output_type>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,t.jsx)(e.h4,{id:"imu-sensor",children:"IMU Sensor"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-xml",children:'<gazebo reference="imu_link">\n  <sensor name="humanoid_imu" type="imu">\n    <always_on>true</always_on>\n    <update_rate>100</update_rate>\n    <visualize>false</visualize>\n    <imu>\n      <angular_velocity>\n        <x>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>2e-4</stddev>\n          </noise>\n        </x>\n        <y>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>2e-4</stddev>\n          </noise>\n        </y>\n        <z>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>2e-4</stddev>\n          </noise>\n        </z>\n      </angular_velocity>\n      <linear_acceleration>\n        <x>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>1.7e-2</stddev>\n          </noise>\n        </x>\n        <y>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>1.7e-2</stddev>\n          </noise>\n        </y>\n        <z>\n          <noise type="gaussian">\n            <mean>0.0</mean>\n            <stddev>1.7e-2</stddev>\n          </noise>\n        </z>\n      </linear_acceleration>\n    </imu>\n    <plugin name="imu_controller" filename="libgazebo_ros_imu.so">\n      <ros>\n        <namespace>/humanoid_robot</namespace>\n        <remapping>~/out:=imu/data</remapping>\n      </ros>\n    </plugin>\n  </sensor>\n</gazebo>\n'})}),"\n",(0,t.jsx)(e.h2,{id:"unity-integration-for-high-fidelity-visualization",children:"Unity Integration for High-Fidelity Visualization"}),"\n",(0,t.jsx)(e.p,{children:"Unity provides a high-fidelity 3D environment that can be used alongside Gazebo for more realistic visualization and testing. Unity Robotics provides tools for connecting Unity with ROS 2."}),"\n",(0,t.jsx)(i,{title:"Simulation Architecture Overview",description:"A diagram showing the architecture of the simulation system. On the left is the ROS 2 ecosystem with nodes for robot control, sensor processing, and planning. In the center is the Gazebo simulation environment containing the humanoid robot model with various sensors (LiDAR, IMU, cameras). On the right is the Unity visualization environment showing the same robot in a high-fidelity 3D environment. Bidirectional arrows show communication between ROS 2 and both simulation environments.",children:(0,t.jsx)(e.p,{children:(0,t.jsx)(e.img,{src:"/img/diagrams/simulation-architecture.svg",alt:"Simulation Architecture"})})}),"\n",(0,t.jsx)(e.h3,{id:"unity-ros-2-bridge-setup",children:"Unity-ROS 2 Bridge Setup"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Install Unity Hub and Unity Editor (2021.3 LTS or newer)"}),"\n",(0,t.jsx)(e.li,{children:"Import the Unity Robotics Hub package"}),"\n",(0,t.jsx)(e.li,{children:"Use the ROS-TCP-Connector to establish communication between Unity and ROS 2"}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"basic-unity-ros-2-connection",children:"Basic Unity-ROS 2 Connection"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-csharp",children:'using UnityEngine;\nusing Unity.Robotics.ROSTCPConnector;\nusing RosMessageTypes.Sensor;\n\npublic class RobotController : MonoBehaviour\n{\n    private ROSConnection ros;\n    private string robotTopic = "/unity_robot/joint_commands";\n\n    void Start()\n    {\n        ros = ROSConnection.GetOrCreateInstance();\n        ros.RegisterPublisher<JointStateMsg>(robotTopic);\n    }\n\n    void Update()\n    {\n        // Send joint commands to ROS\n        var jointMsg = new JointStateMsg();\n        jointMsg.name = new string[] { "hip_joint", "knee_joint" };\n        jointMsg.position = new double[] { Mathf.Sin(Time.time), Mathf.Cos(Time.time) };\n\n        ros.Publish(robotTopic, jointMsg);\n    }\n}\n'})}),"\n",(0,t.jsx)(e.h2,{id:"creating-a-simulation-environment",children:"Creating a Simulation Environment"}),"\n",(0,t.jsx)(e.h3,{id:"launch-file-for-gazebo-simulation",children:"Launch File for Gazebo Simulation"}),"\n",(0,t.jsx)(e.p,{children:"Create a launch file to start your humanoid robot simulation:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-python",children:"import os\nfrom launch import LaunchDescription\nfrom launch.actions import DeclareLaunchArgument, IncludeLaunchDescription\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch.substitutions import LaunchConfiguration\nfrom launch_ros.actions import Node\nfrom ament_index_python.packages import get_package_share_directory\n\ndef generate_launch_description():\n    # Get the package directory\n    pkg_gazebo_ros = get_package_share_directory('gazebo_ros')\n    pkg_humanoid_description = get_package_share_directory('humanoid_description')\n\n    # Simulation arguments\n    use_sim_time = LaunchConfiguration('use_sim_time', default='true')\n    world = LaunchConfiguration('world', default=os.path.join(\n        pkg_humanoid_description, 'worlds', 'simple_room.sdf'\n    ))\n\n    # Launch Gazebo\n    gazebo = IncludeLaunchDescription(\n        PythonLaunchDescriptionSource(\n            os.path.join(pkg_gazebo_ros, 'launch', 'gazebo.launch.py')\n        ),\n        launch_arguments={\n            'world': world,\n            'verbose': 'false',\n        }.items()\n    )\n\n    # Spawn the robot in Gazebo\n    spawn_entity = Node(\n        package='gazebo_ros',\n        executable='spawn_entity.py',\n        arguments=[\n            '-topic', 'robot_description',\n            '-entity', 'humanoid_robot'\n        ],\n        output='screen'\n    )\n\n    return LaunchDescription([\n        DeclareLaunchArgument(\n            'use_sim_time',\n            default_value='true',\n            description='Use simulation (Gazebo) clock if true'\n        ),\n        DeclareLaunchArgument(\n            'world',\n            default_value=os.path.join(pkg_humanoid_description, 'worlds', 'simple_room.sdf'),\n            description='SDF world file'\n        ),\n        gazebo,\n        spawn_entity,\n    ])\n"})}),"\n",(0,t.jsx)(e.h2,{id:"running-the-simulation",children:"Running the Simulation"}),"\n",(0,t.jsx)(e.h3,{id:"starting-the-simulation",children:"Starting the Simulation"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Build your ROS 2 workspace:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"cd ~/ros2_ws\ncolcon build --packages-select humanoid_description\nsource install/setup.bash\n"})}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"Launch the simulation:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"ros2 launch humanoid_description.launch.py\n"})}),"\n"]}),"\n",(0,t.jsxs)(e.li,{children:["\n",(0,t.jsx)(e.p,{children:"In another terminal, run RViz to visualize the robot:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"rviz2\n"})}),"\n"]}),"\n"]}),"\n",(0,t.jsx)(e.h3,{id:"verifying-sensor-data",children:"Verifying Sensor Data"}),"\n",(0,t.jsx)(e.p,{children:"Check that your simulated sensors are publishing data:"}),"\n",(0,t.jsx)(e.pre,{children:(0,t.jsx)(e.code,{className:"language-bash",children:"# Check available topics\nros2 topic list\n\n# View LiDAR data\nros2 topic echo /humanoid_robot/scan\n\n# View IMU data\nros2 topic echo /humanoid_robot/imu/data\n"})}),"\n",(0,t.jsx)(e.h2,{id:"practice-tasks",children:"Practice Tasks"}),"\n",(0,t.jsxs)(e.ol,{children:["\n",(0,t.jsx)(e.li,{children:"Create a complete URDF model for a simple humanoid robot with at least 10 joints"}),"\n",(0,t.jsx)(e.li,{children:"Set up a Gazebo simulation environment with obstacles"}),"\n",(0,t.jsx)(e.li,{children:"Add a LiDAR sensor to your robot and verify it publishes scan data"}),"\n",(0,t.jsx)(e.li,{children:"Implement a simple walking gait simulation using joint position control"}),"\n",(0,t.jsx)(e.li,{children:"Create a Unity scene that mirrors the Gazebo simulation with the same robot model"}),"\n"]}),"\n",(0,t.jsx)(e.h2,{id:"summary",children:"Summary"}),"\n",(0,t.jsx)(e.p,{children:"In this chapter, you've learned how to create and work with digital twins of humanoid robots using Gazebo and Unity. You now understand:"}),"\n",(0,t.jsxs)(e.ul,{children:["\n",(0,t.jsx)(e.li,{children:"How to set up physics simulation environments"}),"\n",(0,t.jsx)(e.li,{children:"How to integrate sensors into your robot models"}),"\n",(0,t.jsx)(e.li,{children:"How to connect simulation environments with ROS 2"}),"\n",(0,t.jsx)(e.li,{children:"How to verify that your simulated robot behaves as expected"}),"\n"]}),"\n",(0,t.jsx)(e.p,{children:"Digital twins are essential for developing and testing humanoid robots safely and efficiently. The skills you've learned in this chapter will be crucial as you move on to implementing AI control systems in the next chapter."})]})}function u(n={}){const{wrapper:e}={...(0,a.R)(),...n.components};return e?(0,t.jsx)(e,{...n,children:(0,t.jsx)(d,{...n})}):d(n)}},8453:(n,e,i)=>{i.d(e,{R:()=>s,x:()=>r});var o=i(6540);const t={},a=o.createContext(t);function s(n){const e=o.useContext(a);return o.useMemo(function(){return"function"==typeof n?n(e):{...e,...n}},[e,n])}function r(n){let e;return e=n.disableParentContext?"function"==typeof n.components?n.components(t):n.components||t:s(n.components),o.createElement(a.Provider,{value:e},n.children)}}}]);